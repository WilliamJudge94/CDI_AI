{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sfu0Pla9EiS"
   },
   "source": [
    "# Start Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zpx-9Ztt8lTo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import autokeras as ak\n",
    "\n",
    "# Use the 0th GPU in the computer\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4skpTKbI8oud"
   },
   "outputs": [],
   "source": [
    "def norma2(input_data):\n",
    "    \"\"\"Normalize all data based on their own max values\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    input_data - (np.array)\n",
    "        the full array of all 2D images to normalize based upon their own np.max value\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    The normalized data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    maxies = np.max(input_data, axis=(1,2))\n",
    "    if np.count_nonzero(maxies) != len(input_data):\n",
    "        print('Error - Divide By Zero Found')\n",
    "    output = np.divide(input_data, maxies[:,None, None])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xm5DZCD-8rCW"
   },
   "outputs": [],
   "source": [
    "# Load in the already split Training and Test Sets 64x64 image dataset\n",
    "\n",
    "xTrain = np.load('../training_data/noise_train_datatset_01.npy', allow_pickle=True)\n",
    "yTrain = np.load('../training_data/noise_train_labels_01.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7C-7WXx8uw4",
    "outputId": "118f195b-445e-4a3b-ced3-b30581bb43a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88128, 64, 64), (88128, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain every nth data point for faster training\n",
    "new_xTrain2 = []\n",
    "new_yTrain2 = []\n",
    "\n",
    "for kk, value in enumerate(xTrain):\n",
    "    if kk%2 == 0:\n",
    "        new_xTrain2.append(value)\n",
    "        new_yTrain2.append(yTrain[kk])\n",
    "        \n",
    "new_xTrain2 = np.asarray(new_xTrain2)\n",
    "new_yTrain2 = np.asarray(new_yTrain2)\n",
    "\n",
    "xTrain = new_xTrain2\n",
    "yTrain = new_yTrain2\n",
    "\n",
    "new_xTrain2.shape, new_yTrain2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjAekfu4BpIl",
    "outputId": "c0016aff-c7f5-44e2-8bb7-ab44a1fd42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74908, 64, 64) float64 (13220, 64, 64) float64\n"
     ]
    }
   ],
   "source": [
    "# Section out Perfect - Edge - Screw - Training Testing\n",
    "perf_dat = []\n",
    "edge_dat = []\n",
    "screw_dat = []\n",
    "\n",
    "perf_lab = []\n",
    "edge_lab = []\n",
    "screw_lab = []\n",
    "\n",
    "\n",
    "for idx, labels in enumerate(yTrain):\n",
    "    if labels[0] == 1:\n",
    "        perf_lab.append(labels)\n",
    "        perf_dat.append(xTrain[idx])\n",
    "    \n",
    "    elif labels[1] == 1:\n",
    "        edge_lab.append(labels)\n",
    "        edge_dat.append(xTrain[idx])\n",
    "        \n",
    "    elif labels[2] == 1:\n",
    "        screw_lab.append(labels)\n",
    "        screw_dat.append(xTrain[idx])\n",
    "\n",
    "        \n",
    "perf_dat = np.asarray(perf_dat)\n",
    "edge_dat = np.asarray(edge_dat)\n",
    "screw_dat = np.asarray(screw_dat)\n",
    "\n",
    "perf_lab = np.asarray(perf_lab)\n",
    "edge_lab = np.asarray(edge_lab)\n",
    "screw_lab = np.asarray(screw_lab)\n",
    "\n",
    "\n",
    "X_train = np.vstack((perf_dat, edge_dat, screw_dat))\n",
    "y_train = np.vstack((perf_lab, edge_lab, screw_lab))\n",
    "\n",
    "#print('ONLY HAS EDGE AND SCREW DATA!!!!')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X_train, \n",
    "                                                y_train, \n",
    "                                                test_size = 0.15, \n",
    "                                                random_state = 0)\n",
    "\n",
    "print(xTrain.shape, xTrain.dtype, xTest.shape, xTest.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXNVDDBX8zxj",
    "outputId": "8d5707f4-cb85-4bc6-a6aa-cab93d494097"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74908, 64, 64, 3),\n",
       " (74908, 3),\n",
       " (13220, 64, 64, 3),\n",
       " (13220, 3),\n",
       " dtype('float64'),\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.asarray(yTrain)\n",
    "y_test = np.asarray(yTest)\n",
    "\n",
    "\n",
    "X_train = norma2(xTrain)\n",
    "X_test = norma2(xTest)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 64, 64, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 64, 64, 1))\n",
    "\n",
    "X_train = np.asarray(np.repeat(X_train, 3, 3))\n",
    "X_test = np.asarray(np.repeat(X_test, 3, 3))\n",
    "\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_train.dtype, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6ikv0i3Ig9u"
   },
   "outputs": [],
   "source": [
    "# Saves on RAM\n",
    "del edge_dat\n",
    "del screw_dat\n",
    "del perf_dat\n",
    "\n",
    "del new_xTrain2\n",
    "del edge_lab\n",
    "del screw_lab\n",
    "del perf_lab\n",
    "del new_yTrain2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8f2NpNRyGub"
   },
   "source": [
    "# ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip36rDaMyiQB"
   },
   "outputs": [],
   "source": [
    "# Set Values\n",
    "rot_ran = 5\n",
    "shear_range = 0.3\n",
    "zoom_ran = [0.75, 1.25]\n",
    "width_shift_ran = 0.10 #0.3\n",
    "height_shift_ran = 0.10 #0.3\n",
    "horz_flip = True\n",
    "vert_flip = True\n",
    "fill_mod = 'constant'\n",
    "fill_val = 0.0\n",
    "\n",
    "\n",
    "bright_ran = [0.9, 1.1]\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def nan_check(img):\n",
    "    \"\"\"Used in post ImageDataGenerator processing to determine if there is a np.nan\n",
    "    in the image\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    img - (np.array)\n",
    "        2D image array\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    The input image, but will print out 'NAN IN ARRAY' for the users if found\n",
    "    \n",
    "    \"\"\"\n",
    "    if np.isnan(np.sum(xTest[0])):\n",
    "        print('NAN IN ARRAY!!!')\n",
    "        sys.stdout.flush()\n",
    "    return img/255.0\n",
    "\n",
    "def nan_check2(img):\n",
    "    \"\"\"Used in post ImageDataGenerator processing to determine if there is a np.nan\n",
    "    in the image\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    img - (np.array)\n",
    "        2D image array\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    The input image, but will print out 'NAN IN ARRAY' for the users if found\n",
    "    \n",
    "    \"\"\"\n",
    "    if np.isnan(np.sum(xTest[0])):\n",
    "        print('NAN IN ARRAY!!!')\n",
    "        sys.stdout.flush()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DYRXBIHyip2"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "    rotation_range=rot_ran,\n",
    "    shear_range=shear_range,\n",
    "    zoom_range=zoom_ran,\n",
    "    width_shift_range=width_shift_ran,\n",
    "    height_shift_range=height_shift_ran,\n",
    "    horizontal_flip=horz_flip,\n",
    "    vertical_flip=vert_flip,\n",
    "    \n",
    "    brightness_range=bright_ran,\n",
    "\n",
    "    fill_mode=fill_mod,\n",
    "    cval=fill_val,\n",
    "\n",
    "    \n",
    "    preprocessing_function=nan_check,\n",
    "    validation_split=0.1)\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    \n",
    "    #rotation_range=rot_ran,\n",
    "    #shear_range=shear_range,\n",
    "    #zoom_range=zoom_ran,\n",
    "    #width_shift_range=width_shift_ran,\n",
    "    #height_shift_range=height_shift_ran,\n",
    "    #horizontal_flip=horz_flip,\n",
    "    #vertical_flip=vert_flip,\n",
    "    \n",
    "    fill_mode=fill_mod,\n",
    "    cval=fill_val,\n",
    "    \n",
    "    preprocessing_function=nan_check2,\n",
    "    validation_split=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IBC_YU0zG8o",
    "outputId": "2f3da7b9-e2ed-4a22-ac06-42bc5d22922b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74908, 64, 64, 3),\n",
       " (74908, 3),\n",
       " (13220, 64, 64, 3),\n",
       " (13220, 3),\n",
       " dtype('float64'),\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_train.dtype, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvSJD-OAzl01"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wDXLFMWyIUq"
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_gen = train_datagen.flow(X_train, y_train, \n",
    "                                 batch_size=batch_size, \n",
    "                                 shuffle=True,\n",
    "                                 subset='training', seed=7)\n",
    "\n",
    "\n",
    "v_gen = val_datagen.flow(X_test, y_test,\n",
    "                                 batch_size=batch_size,\n",
    "                                 subset='training', seed=7)\n",
    "\n",
    "\n",
    "\n",
    "ds = tf.data.Dataset.from_generator(lambda: train_gen, \n",
    "    output_types=(tf.float32, tf.float32), \n",
    "    output_shapes=([None,64,64,3], [None,3])\n",
    ")\n",
    "\n",
    "\n",
    "v = tf.data.Dataset.from_generator(lambda: v_gen, \n",
    "    output_types=(tf.float32, tf.float32), \n",
    "    output_shapes=([None,64,64,3], [None,3])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyA3v0r9ahEG"
   },
   "source": [
    "# AutoKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6_q5g7dDJII"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('../untrained_model-Autokeras/')\n",
    "\n",
    "\n",
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "      (i.e., the weights have the same distribution along each dimension).\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "      If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    # Faster, but less random: only permutes along the first dimension\n",
    "    # weights = [np.random.permutation(w) for w in weights]\n",
    "    model.set_weights(weights)\n",
    "\n",
    "shuffle_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "FbrW_-mTEX4_",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b09a5314-d846-44eb-a5f3-fd70c65695db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Will_CDI_Project/paper/autok_training/100-200_train/{epoch:02d}-{val_loss:.7f}.hdf5\n",
      "Train for 2107 steps, validate for 409 steps\n",
      "Epoch 1/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
      "Epoch 2/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 3/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0098 - val_accuracy: 0.9966\n",
      "Epoch 4/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0357 - val_accuracy: 0.9871\n",
      "Epoch 5/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0119 - val_accuracy: 0.9960\n",
      "Epoch 6/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0097 - val_accuracy: 0.9972\n",
      "Epoch 7/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0102 - val_accuracy: 0.9968\n",
      "Epoch 8/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9952\n",
      "Epoch 9/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
      "Epoch 10/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0113 - val_accuracy: 0.9963\n",
      "Epoch 11/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0109 - val_accuracy: 0.9966\n",
      "Epoch 12/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1521 - val_accuracy: 0.9833\n",
      "Epoch 13/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0035 - val_accuracy: 0.9985\n",
      "Epoch 14/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 15/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 16/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
      "Epoch 17/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0078 - val_accuracy: 0.9977\n",
      "Epoch 18/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0047 - val_accuracy: 0.9982\n",
      "Epoch 19/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0121 - val_accuracy: 0.9963\n",
      "Epoch 20/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0059 - val_accuracy: 0.9974\n",
      "Epoch 21/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0424 - val_accuracy: 0.9906\n",
      "Epoch 22/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 23/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0216 - val_accuracy: 0.9927\n",
      "Epoch 24/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0061 - val_accuracy: 0.9974\n",
      "Epoch 25/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0049 - val_accuracy: 0.9982\n",
      "Epoch 26/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 27/100\n",
      "2107/2107 [==============================] - 144s 69ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "Epoch 28/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0028 - val_accuracy: 0.9994\n",
      "Epoch 29/100\n",
      "2107/2107 [==============================] - 144s 68ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0074 - val_accuracy: 0.9972\n",
      "Epoch 30/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 31/100\n",
      "2107/2107 [==============================] - 144s 68ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
      "Epoch 33/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
      "Epoch 34/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 0.9989\n",
      "Epoch 35/100\n",
      "2107/2107 [==============================] - 142s 68ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0073 - val_accuracy: 0.9978\n",
      "Epoch 36/100\n",
      "2107/2107 [==============================] - 144s 68ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0073 - val_accuracy: 0.9975\n",
      "Epoch 37/100\n",
      "2107/2107 [==============================] - 144s 68ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 38/100\n",
      "2107/2107 [==============================] - 144s 68ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0039 - val_accuracy: 0.9982\n",
      "Epoch 39/100\n",
      "2107/2107 [==============================] - 142s 67ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0105 - val_accuracy: 0.9956\n",
      "Epoch 40/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0036 - val_accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 42/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 43/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0095 - val_accuracy: 0.9968\n",
      "Epoch 44/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0042 - val_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0226 - val_accuracy: 0.9925\n",
      "Epoch 46/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0166 - val_accuracy: 0.9947\n",
      "Epoch 47/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0117 - val_accuracy: 0.9958\n",
      "Epoch 48/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0060 - val_accuracy: 0.9982\n",
      "Epoch 49/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0055 - val_accuracy: 0.9977\n",
      "Epoch 50/100\n",
      "2107/2107 [==============================] - 138s 65ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0199 - val_accuracy: 0.9942\n",
      "Epoch 51/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.0065 - val_accuracy: 0.9973\n",
      "Epoch 52/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
      "Epoch 53/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0672 - val_accuracy: 0.9811\n",
      "Epoch 54/100\n",
      "2107/2107 [==============================] - 142s 67ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9982\n",
      "Epoch 57/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "2107/2107 [==============================] - 143s 68ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
      "Epoch 59/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0190 - val_accuracy: 0.9921\n",
      "Epoch 60/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9969\n",
      "Epoch 61/100\n",
      "2107/2107 [==============================] - 142s 67ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 62/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0075 - val_accuracy: 0.9992\n",
      "Epoch 64/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0239 - val_accuracy: 0.9970\n",
      "Epoch 65/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0072 - val_accuracy: 0.9971\n",
      "Epoch 66/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 67/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9982\n",
      "Epoch 68/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "Epoch 69/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9978\n",
      "Epoch 70/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0150 - val_accuracy: 0.9941\n",
      "Epoch 71/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "Epoch 72/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0029 - val_accuracy: 0.9984\n",
      "Epoch 73/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 74/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 76/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0032 - val_accuracy: 0.9985\n",
      "Epoch 77/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0169 - val_accuracy: 0.9940\n",
      "Epoch 78/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0093 - val_accuracy: 0.9963\n",
      "Epoch 79/100\n",
      "2107/2107 [==============================] - 138s 65ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 80/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9989\n",
      "Epoch 81/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 82/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 83/100\n",
      "2107/2107 [==============================] - 138s 66ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9971\n",
      "Epoch 84/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
      "Epoch 85/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0054 - val_accuracy: 0.9986\n",
      "Epoch 86/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 0.9969\n",
      "Epoch 87/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
      "Epoch 88/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 89/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 90/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 9.4854e-04 - val_accuracy: 0.9996\n",
      "Epoch 91/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 92/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "Epoch 93/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 95/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "2107/2107 [==============================] - 139s 66ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0039 - val_accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "2107/2107 [==============================] - 140s 66ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 99/100\n",
      "2107/2107 [==============================] - 140s 67ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
      "Epoch 100/100\n",
      "2107/2107 [==============================] - 141s 67ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0155 - val_accuracy: 0.9948\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set some parameters\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "save_dir = '100-200_train'\n",
    "checkpoint_save_path = '/content/drive/MyDrive/Will_CDI_Project/paper/autok_training/'+save_dir+'/{epoch:02d}-{val_loss:.7f}.hdf5'\n",
    "print(checkpoint_save_path)\n",
    "\n",
    "checkpoints = ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                              save_best_only=True,\n",
    "                              save_weights_only=True,\n",
    "                              save_freq='epoch')\n",
    "\n",
    "history = model.fit_generator(ds,\n",
    "      epochs=epochs,  #### set repeat in training dataset\n",
    "      steps_per_epoch=len(train_gen),\n",
    "      validation_data=v,\n",
    "      validation_steps=len(v_gen), \n",
    "      callbacks=[checkpoints, ], \n",
    "      verbose=1)\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "\n",
    "np.savez('/content/drive/MyDrive/Will_CDI_Project/paper/autok_training/100-200_hist/history.npz', val_loss=val_loss, val_acc=val_acc, loss=loss, acc=acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-aJCocp8620"
   },
   "source": [
    "# HandMade - OG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PC_nDp5e878l"
   },
   "outputs": [],
   "source": [
    "# Basic TF Imports\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# MODELS AND OPTIMIZERS\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "Nc = 64\n",
    "n_labels = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(Nc, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(Nc,Nc, 3)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_labels, activation='softmax'))\n",
    "\n",
    "  \n",
    "\n",
    "opto = Adam() \n",
    "model.compile(optimizer=opto, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMuJ1ZOGJTgZ"
   },
   "outputs": [],
   "source": [
    "# Unnessessary for initial training\n",
    "model.load_weights('../trained_model-Handmade/handmade_trained.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handmade - Reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic TF Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# MODELS AND OPTIMIZERS\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                activation='relu',\n",
    "                input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.5)) #0.5\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.5)) #0.5\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) #128\n",
    "#model.add(Dropout(0.25)) #0.25\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = 'adam'\n",
    "learning_rate = 0.0005\n",
    "if optimizer == \"adam\":\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "elif optimizer == \"sgd\":\n",
    "    optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "elif optimizer=='rmsprop':\n",
    "    optimizer = tf.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "else:\n",
    "    raise ValueError(\"unexpected optimizer name: %r\" % (optimizer_name,))\n",
    "  \n",
    "model.compile(optimizer=optimizer,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "hjqQDGms_VJ_",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1c87b404-bdce-4ea6-b528-e1ded4a47409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Will_CDI_Project/paper/handmade/100-200_train/{epoch:02d}-{val_loss:.7f}.hdf5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2107/2107 [==============================] - 105s 47ms/step - loss: 0.2700 - accuracy: 0.8808 - val_loss: 0.1727 - val_accuracy: 0.9309\n",
      "Epoch 2/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2658 - accuracy: 0.8834 - val_loss: 0.1606 - val_accuracy: 0.9438\n",
      "Epoch 3/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2664 - accuracy: 0.8808 - val_loss: 0.1554 - val_accuracy: 0.9451\n",
      "Epoch 4/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2667 - accuracy: 0.8813 - val_loss: 0.1409 - val_accuracy: 0.9518\n",
      "Epoch 5/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2638 - accuracy: 0.8828 - val_loss: 0.1718 - val_accuracy: 0.9331\n",
      "Epoch 6/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2655 - accuracy: 0.8832 - val_loss: 0.1487 - val_accuracy: 0.9454\n",
      "Epoch 7/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2702 - accuracy: 0.8825 - val_loss: 0.1516 - val_accuracy: 0.9465\n",
      "Epoch 8/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2670 - accuracy: 0.8831 - val_loss: 0.1707 - val_accuracy: 0.9377\n",
      "Epoch 9/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2626 - accuracy: 0.8811 - val_loss: 0.1614 - val_accuracy: 0.9330\n",
      "Epoch 10/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2659 - accuracy: 0.8825 - val_loss: 0.1583 - val_accuracy: 0.9397\n",
      "Epoch 11/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2623 - accuracy: 0.8814 - val_loss: 0.1549 - val_accuracy: 0.9435\n",
      "Epoch 12/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2627 - accuracy: 0.8811 - val_loss: 0.1484 - val_accuracy: 0.9446\n",
      "Epoch 13/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2582 - accuracy: 0.8855 - val_loss: 0.1556 - val_accuracy: 0.9385\n",
      "Epoch 14/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2618 - accuracy: 0.8847 - val_loss: 0.1464 - val_accuracy: 0.9447\n",
      "Epoch 15/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2576 - accuracy: 0.8863 - val_loss: 0.1667 - val_accuracy: 0.9364\n",
      "Epoch 16/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2631 - accuracy: 0.8838 - val_loss: 0.1671 - val_accuracy: 0.9462\n",
      "Epoch 17/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2522 - accuracy: 0.8892 - val_loss: 0.1361 - val_accuracy: 0.9498\n",
      "Epoch 18/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2623 - accuracy: 0.8852 - val_loss: 0.1504 - val_accuracy: 0.9436\n",
      "Epoch 19/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2593 - accuracy: 0.8847 - val_loss: 0.1255 - val_accuracy: 0.9604\n",
      "Epoch 20/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2614 - accuracy: 0.8838 - val_loss: 0.1479 - val_accuracy: 0.9411\n",
      "Epoch 21/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2573 - accuracy: 0.8849 - val_loss: 0.1612 - val_accuracy: 0.9361\n",
      "Epoch 22/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2559 - accuracy: 0.8878 - val_loss: 0.1469 - val_accuracy: 0.9437\n",
      "Epoch 23/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2541 - accuracy: 0.8891 - val_loss: 0.1695 - val_accuracy: 0.9273\n",
      "Epoch 24/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2599 - accuracy: 0.8874 - val_loss: 0.1384 - val_accuracy: 0.9490\n",
      "Epoch 25/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2557 - accuracy: 0.8889 - val_loss: 0.1322 - val_accuracy: 0.9524\n",
      "Epoch 26/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2556 - accuracy: 0.8882 - val_loss: 0.1298 - val_accuracy: 0.9542\n",
      "Epoch 27/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2509 - accuracy: 0.8905 - val_loss: 0.1531 - val_accuracy: 0.9435\n",
      "Epoch 28/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2527 - accuracy: 0.8902 - val_loss: 0.1501 - val_accuracy: 0.9445\n",
      "Epoch 29/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2514 - accuracy: 0.8899 - val_loss: 0.1507 - val_accuracy: 0.9462\n",
      "Epoch 30/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2560 - accuracy: 0.8893 - val_loss: 0.1219 - val_accuracy: 0.9584\n",
      "Epoch 31/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2539 - accuracy: 0.8897 - val_loss: 0.1425 - val_accuracy: 0.9564\n",
      "Epoch 32/100\n",
      "2107/2107 [==============================] - 99s 47ms/step - loss: 0.2467 - accuracy: 0.8921 - val_loss: 0.1546 - val_accuracy: 0.9441\n",
      "Epoch 33/100\n",
      "2107/2107 [==============================] - 99s 47ms/step - loss: 0.2539 - accuracy: 0.8894 - val_loss: 0.1175 - val_accuracy: 0.9601\n",
      "Epoch 34/100\n",
      "2107/2107 [==============================] - 99s 47ms/step - loss: 0.2522 - accuracy: 0.8904 - val_loss: 0.1343 - val_accuracy: 0.9551\n",
      "Epoch 35/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2580 - accuracy: 0.8875 - val_loss: 0.1793 - val_accuracy: 0.9305\n",
      "Epoch 36/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2520 - accuracy: 0.8906 - val_loss: 0.1251 - val_accuracy: 0.9573\n",
      "Epoch 37/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2552 - accuracy: 0.8878 - val_loss: 0.1569 - val_accuracy: 0.9355\n",
      "Epoch 38/100\n",
      "2107/2107 [==============================] - 100s 47ms/step - loss: 0.2479 - accuracy: 0.8919 - val_loss: 0.1251 - val_accuracy: 0.9518\n",
      "Epoch 39/100\n",
      "2107/2107 [==============================] - 99s 47ms/step - loss: 0.2530 - accuracy: 0.8900 - val_loss: 0.1305 - val_accuracy: 0.9547\n",
      "Epoch 40/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2541 - accuracy: 0.8886 - val_loss: 0.1281 - val_accuracy: 0.9551\n",
      "Epoch 41/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2468 - accuracy: 0.8916 - val_loss: 0.1573 - val_accuracy: 0.9409\n",
      "Epoch 42/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2419 - accuracy: 0.8936 - val_loss: 0.1227 - val_accuracy: 0.9551\n",
      "Epoch 43/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2489 - accuracy: 0.8934 - val_loss: 0.1212 - val_accuracy: 0.9561\n",
      "Epoch 44/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2486 - accuracy: 0.8920 - val_loss: 0.1394 - val_accuracy: 0.9503\n",
      "Epoch 45/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2442 - accuracy: 0.8930 - val_loss: 0.1428 - val_accuracy: 0.9487\n",
      "Epoch 46/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2477 - accuracy: 0.8931 - val_loss: 0.1375 - val_accuracy: 0.9539\n",
      "Epoch 47/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2468 - accuracy: 0.8921 - val_loss: 0.1192 - val_accuracy: 0.9579\n",
      "Epoch 48/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2468 - accuracy: 0.8935 - val_loss: 0.1239 - val_accuracy: 0.9589\n",
      "Epoch 49/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2443 - accuracy: 0.8932 - val_loss: 0.1214 - val_accuracy: 0.9563\n",
      "Epoch 50/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2523 - accuracy: 0.8922 - val_loss: 0.1518 - val_accuracy: 0.9461\n",
      "Epoch 51/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2484 - accuracy: 0.8929 - val_loss: 0.1102 - val_accuracy: 0.9646\n",
      "Epoch 52/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2408 - accuracy: 0.8970 - val_loss: 0.1461 - val_accuracy: 0.9499\n",
      "Epoch 53/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2423 - accuracy: 0.8951 - val_loss: 0.1370 - val_accuracy: 0.9540\n",
      "Epoch 54/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2543 - accuracy: 0.8914 - val_loss: 0.1294 - val_accuracy: 0.9563\n",
      "Epoch 55/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2404 - accuracy: 0.8955 - val_loss: 0.1453 - val_accuracy: 0.9463\n",
      "Epoch 56/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2437 - accuracy: 0.8939 - val_loss: 0.1220 - val_accuracy: 0.9620\n",
      "Epoch 57/100\n",
      "2107/2107 [==============================] - 101s 48ms/step - loss: 0.2445 - accuracy: 0.8944 - val_loss: 0.1166 - val_accuracy: 0.9636\n",
      "Epoch 58/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2422 - accuracy: 0.8959 - val_loss: 0.1354 - val_accuracy: 0.9530\n",
      "Epoch 59/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2432 - accuracy: 0.8955 - val_loss: 0.1113 - val_accuracy: 0.9668\n",
      "Epoch 60/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2405 - accuracy: 0.8973 - val_loss: 0.1345 - val_accuracy: 0.9559\n",
      "Epoch 61/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2466 - accuracy: 0.8943 - val_loss: 0.1279 - val_accuracy: 0.9590\n",
      "Epoch 62/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2420 - accuracy: 0.8965 - val_loss: 0.1279 - val_accuracy: 0.9581\n",
      "Epoch 63/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2405 - accuracy: 0.8953 - val_loss: 0.1154 - val_accuracy: 0.9598\n",
      "Epoch 64/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2374 - accuracy: 0.8982 - val_loss: 0.1414 - val_accuracy: 0.9505\n",
      "Epoch 65/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2426 - accuracy: 0.8949 - val_loss: 0.1333 - val_accuracy: 0.9551\n",
      "Epoch 66/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2420 - accuracy: 0.8975 - val_loss: 0.1302 - val_accuracy: 0.9546\n",
      "Epoch 67/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2360 - accuracy: 0.8989 - val_loss: 0.1089 - val_accuracy: 0.9642\n",
      "Epoch 68/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2413 - accuracy: 0.8967 - val_loss: 0.1357 - val_accuracy: 0.9493\n",
      "Epoch 69/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2374 - accuracy: 0.8956 - val_loss: 0.1164 - val_accuracy: 0.9579\n",
      "Epoch 70/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2375 - accuracy: 0.9003 - val_loss: 0.1349 - val_accuracy: 0.9531\n",
      "Epoch 71/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2428 - accuracy: 0.8968 - val_loss: 0.1562 - val_accuracy: 0.9484\n",
      "Epoch 72/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2359 - accuracy: 0.8992 - val_loss: 0.1242 - val_accuracy: 0.9522\n",
      "Epoch 73/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2423 - accuracy: 0.8963 - val_loss: 0.1092 - val_accuracy: 0.9655\n",
      "Epoch 74/100\n",
      "2107/2107 [==============================] - 100s 47ms/step - loss: 0.2372 - accuracy: 0.8993 - val_loss: 0.1163 - val_accuracy: 0.9626\n",
      "Epoch 75/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2330 - accuracy: 0.8988 - val_loss: 0.1023 - val_accuracy: 0.9655\n",
      "Epoch 76/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2354 - accuracy: 0.8981 - val_loss: 0.1138 - val_accuracy: 0.9613\n",
      "Epoch 77/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2403 - accuracy: 0.8981 - val_loss: 0.1199 - val_accuracy: 0.9568\n",
      "Epoch 78/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2404 - accuracy: 0.8969 - val_loss: 0.1310 - val_accuracy: 0.9623\n",
      "Epoch 79/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2367 - accuracy: 0.8979 - val_loss: 0.1145 - val_accuracy: 0.9668\n",
      "Epoch 80/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2406 - accuracy: 0.8975 - val_loss: 0.1084 - val_accuracy: 0.9642\n",
      "Epoch 81/100\n",
      "2107/2107 [==============================] - 100s 47ms/step - loss: 0.2404 - accuracy: 0.8969 - val_loss: 0.1152 - val_accuracy: 0.9621\n",
      "Epoch 82/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2413 - accuracy: 0.8955 - val_loss: 0.1149 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2372 - accuracy: 0.8966 - val_loss: 0.1295 - val_accuracy: 0.9531\n",
      "Epoch 84/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2336 - accuracy: 0.9004 - val_loss: 0.1210 - val_accuracy: 0.9557\n",
      "Epoch 85/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2351 - accuracy: 0.8999 - val_loss: 0.1160 - val_accuracy: 0.9600\n",
      "Epoch 86/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2398 - accuracy: 0.8976 - val_loss: 0.1476 - val_accuracy: 0.9405\n",
      "Epoch 87/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2368 - accuracy: 0.8974 - val_loss: 0.1252 - val_accuracy: 0.9539\n",
      "Epoch 88/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2361 - accuracy: 0.8995 - val_loss: 0.1271 - val_accuracy: 0.9519\n",
      "Epoch 89/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2367 - accuracy: 0.8980 - val_loss: 0.1121 - val_accuracy: 0.9584\n",
      "Epoch 90/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2409 - accuracy: 0.9000 - val_loss: 0.1118 - val_accuracy: 0.9615\n",
      "Epoch 91/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2385 - accuracy: 0.8971 - val_loss: 0.1119 - val_accuracy: 0.9654\n",
      "Epoch 92/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2351 - accuracy: 0.9002 - val_loss: 0.1275 - val_accuracy: 0.9636\n",
      "Epoch 93/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2400 - accuracy: 0.8984 - val_loss: 0.1293 - val_accuracy: 0.9540\n",
      "Epoch 94/100\n",
      "2107/2107 [==============================] - 97s 46ms/step - loss: 0.2382 - accuracy: 0.8958 - val_loss: 0.1194 - val_accuracy: 0.9582\n",
      "Epoch 95/100\n",
      "2107/2107 [==============================] - 98s 46ms/step - loss: 0.2438 - accuracy: 0.8956 - val_loss: 0.1136 - val_accuracy: 0.9616\n",
      "Epoch 96/100\n",
      "2107/2107 [==============================] - 99s 47ms/step - loss: 0.2329 - accuracy: 0.8990 - val_loss: 0.1126 - val_accuracy: 0.9616\n",
      "Epoch 97/100\n",
      "2107/2107 [==============================] - 101s 48ms/step - loss: 0.2369 - accuracy: 0.8986 - val_loss: 0.1394 - val_accuracy: 0.9511\n",
      "Epoch 98/100\n",
      "2107/2107 [==============================] - 99s 47ms/step - loss: 0.2321 - accuracy: 0.9018 - val_loss: 0.1185 - val_accuracy: 0.9638\n",
      "Epoch 99/100\n",
      "2107/2107 [==============================] - 98s 47ms/step - loss: 0.2369 - accuracy: 0.8986 - val_loss: 0.1052 - val_accuracy: 0.9641\n",
      "Epoch 100/100\n",
      "2107/2107 [==============================] - 99s 47ms/step - loss: 0.2378 - accuracy: 0.8990 - val_loss: 0.1348 - val_accuracy: 0.9494\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set some parameters\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "save_dir = '100-200_train'\n",
    "checkpoint_save_path = '/content/drive/MyDrive/Will_CDI_Project/paper/handmade/'+save_dir+'/{epoch:02d}-{val_loss:.7f}.hdf5'\n",
    "print(checkpoint_save_path)\n",
    "\n",
    "checkpoints = ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                              save_best_only=True,\n",
    "                              save_weights_only=True,\n",
    "                              save_freq='epoch')\n",
    "\n",
    "history = model.fit_generator(ds,\n",
    "      epochs=epochs,  #### set repeat in training dataset\n",
    "      steps_per_epoch=len(train_gen),\n",
    "      validation_data=v,\n",
    "      validation_steps=len(v_gen), \n",
    "      callbacks=[checkpoints, ], \n",
    "      verbose=1)\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "\n",
    "np.savez('/content/drive/MyDrive/Will_CDI_Project/paper/handmade/100-200_hist/history.npz', val_loss=val_loss, val_acc=val_acc, loss=loss, acc=acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-dIHyy_Rgy5"
   },
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-u6aRyyjRr41"
   },
   "outputs": [],
   "source": [
    "# Basic TF Imports\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# MODELS AND OPTIMIZERS\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmY5rZTfRiPn",
    "outputId": "9faaf0f8-74b5-4e8a-fd2b-9303849b0d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "Nc = 64\n",
    "n_labels = 3\n",
    "\n",
    "base_model=VGG16(input_shape=(Nc,Nc,3),\n",
    "                 include_top=False)\n",
    "\n",
    "#base_model.layers.pop() #Pop out the current logistic layer\n",
    "tmp = base_model.output\n",
    "\n",
    "#Add a fully connected layer\n",
    "tmp=Flatten()(tmp)\n",
    "\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(n_labels, activation='softmax')(tmp)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "#Fix the first 17 layers\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False \n",
    "    \n",
    "\n",
    "opto = SGD()\n",
    "    \n",
    "model.compile(optimizer=opto, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WfwHGcNKC_s"
   },
   "outputs": [],
   "source": [
    "# Unnessessary for initial training\n",
    "model.load_weights('../trained_model-VGG16/VGG16_trained.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "XE8cPX7SS3cS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6d1d5f91-bd5b-4d48-cc5b-6d14beb7099b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Will_CDI_Project/paper/vgg/100-200_train/{epoch:02d}-{val_loss:.7f}.hdf5\n",
      "Epoch 1/100\n",
      "   3/2107 [..............................] - ETA: 1:53 - loss: 0.0128 - accuracy: 0.9896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2107/2107 [==============================] - 114s 54ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
      "Epoch 2/100\n",
      "2107/2107 [==============================] - 113s 53ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
      "Epoch 3/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 4/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 5/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0096 - val_accuracy: 0.9968\n",
      "Epoch 6/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0101 - val_accuracy: 0.9965\n",
      "Epoch 7/100\n",
      "2107/2107 [==============================] - 113s 54ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.0090 - val_accuracy: 0.9970\n",
      "Epoch 8/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "Epoch 9/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.0091 - val_accuracy: 0.9965\n",
      "Epoch 10/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 11/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 12/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 13/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0083 - val_accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.0058 - val_accuracy: 0.9981\n",
      "Epoch 15/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
      "Epoch 16/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0041 - val_accuracy: 0.9983\n",
      "Epoch 17/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.0062 - val_accuracy: 0.9978\n",
      "Epoch 18/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0079 - val_accuracy: 0.9972\n",
      "Epoch 19/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 20/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 21/100\n",
      "2107/2107 [==============================] - 115s 54ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0043 - val_accuracy: 0.9984\n",
      "Epoch 22/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0112 - val_accuracy: 0.9958\n",
      "Epoch 23/100\n",
      "2107/2107 [==============================] - 115s 54ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 24/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "2107/2107 [==============================] - 115s 54ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0067 - val_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0080 - val_accuracy: 0.9972\n",
      "Epoch 27/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0150 - val_accuracy: 0.9952\n",
      "Epoch 28/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
      "Epoch 29/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0089 - val_accuracy: 0.9970\n",
      "Epoch 30/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 31/100\n",
      "2107/2107 [==============================] - 115s 54ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0040 - val_accuracy: 0.9985\n",
      "Epoch 32/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Epoch 33/100\n",
      "2107/2107 [==============================] - 115s 54ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 34/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0061 - val_accuracy: 0.9982\n",
      "Epoch 35/100\n",
      "2107/2107 [==============================] - 116s 55ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
      "Epoch 36/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 37/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 38/100\n",
      "2107/2107 [==============================] - 115s 54ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 39/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0081 - val_accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0034 - val_accuracy: 0.9986\n",
      "Epoch 41/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 42/100\n",
      "2107/2107 [==============================] - 110s 52ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 43/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9991\n",
      "Epoch 44/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 45/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
      "Epoch 47/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 48/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 49/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
      "Epoch 50/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0100 - val_accuracy: 0.9967\n",
      "Epoch 51/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 52/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 53/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0081 - val_accuracy: 0.9970\n",
      "Epoch 54/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "2107/2107 [==============================] - 113s 53ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0071 - val_accuracy: 0.9976\n",
      "Epoch 56/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 57/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0078 - val_accuracy: 0.9972\n",
      "Epoch 58/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0026 - val_accuracy: 0.9989\n",
      "Epoch 59/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 60/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0019 - val_accuracy: 0.9991\n",
      "Epoch 61/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 63/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
      "Epoch 65/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0056 - val_accuracy: 0.9989\n",
      "Epoch 66/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 68/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
      "Epoch 69/100\n",
      "2107/2107 [==============================] - 110s 52ms/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 7.8092e-04 - val_accuracy: 0.9998\n",
      "Epoch 71/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
      "Epoch 72/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 73/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 74/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 75/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0045 - val_accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
      "Epoch 77/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
      "Epoch 78/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 79/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 80/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 81/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0062 - val_accuracy: 0.9983\n",
      "Epoch 82/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 83/100\n",
      "2107/2107 [==============================] - 115s 55ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 84/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0027 - val_accuracy: 0.9990\n",
      "Epoch 85/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 86/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 88/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 89/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.0053 - val_accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0046 - val_accuracy: 0.9985\n",
      "Epoch 91/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 92/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 93/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 94/100\n",
      "2107/2107 [==============================] - 111s 52ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "2107/2107 [==============================] - 110s 52ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "Epoch 96/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 97/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 98/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0029 - val_accuracy: 0.9988\n",
      "Epoch 99/100\n",
      "2107/2107 [==============================] - 111s 53ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
      "Epoch 100/100\n",
      "2107/2107 [==============================] - 112s 53ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0034 - val_accuracy: 0.9985\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-af211cd68db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Will_CDI_Project/paper/vgg/100-200_hist/history.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavez\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavez\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \"\"\"\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0m_savez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_STORED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     \u001b[0mzipf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mzipfile_factory\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allowZip64'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Will_CDI_Project/paper/vgg/100-200_hist/history.npz'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set some parameters\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "save_dir = '100-200_train'\n",
    "checkpoint_save_path = '/content/drive/MyDrive/Will_CDI_Project/paper/vgg/'+save_dir+'/{epoch:02d}-{val_loss:.7f}.hdf5'\n",
    "print(checkpoint_save_path)\n",
    "\n",
    "checkpoints = ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                              save_best_only=True,\n",
    "                              save_weights_only=True,\n",
    "                              save_freq='epoch')\n",
    "\n",
    "history = model.fit_generator(ds,\n",
    "      epochs=epochs,  #### set repeat in training dataset\n",
    "      steps_per_epoch=len(train_gen),\n",
    "      validation_data=v,\n",
    "      validation_steps=len(v_gen), \n",
    "      callbacks=[checkpoints, ], \n",
    "      verbose=1)\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "\n",
    "np.savez('/content/drive/MyDrive/Will_CDI_Project/paper/vgg/100-200_hist/history.npz', val_loss=val_loss, val_acc=val_acc, loss=loss, acc=acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "F_jt2ZbJ8_BH",
    "CCrj7AXfI55o",
    "1sfu0Pla9EiS",
    "C8f2NpNRyGub",
    "t-aJCocp8620",
    "O7cK4AUT_WNu",
    "Xf00-NqeQLa9",
    "RC0qJQzCIhzd"
   ],
   "machine_shape": "hm",
   "name": "CDI_AI.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
