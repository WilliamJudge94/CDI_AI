{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Imports and Set Up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from time import sleep\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norma2(input_data):\n",
    "    \"\"\"Normalize all data based on their own max values\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    input_data - (np.array)\n",
    "        the full array of all 2D images to normalize based upon their own np.max value\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    The normalized data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    maxies = np.max(input_data, axis=(1,2))\n",
    "    if np.count_nonzero(maxies) != len(input_data):\n",
    "        print('Error - Divide By Zero Found')\n",
    "    output = np.divide(input_data, maxies[:,None, None])\n",
    "\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic TF Imports\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# MODELS AND OPTIMIZERS\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "Nc = 64\n",
    "n_labels = 3\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(Nc, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(Nc,Nc, 3)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_labels, activation='softmax'))\n",
    "\n",
    "opto = Adam() \n",
    "    \n",
    "model.compile(optimizer=opto, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model On Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../../trained_model-Handmade/handmade_trained.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3456    0    0]\n",
      " [   0 2885  571]\n",
      " [   0  773 2683]]\n",
      "[1.0, 0.8347800925925926, 0.7763310185185185]\n",
      "[[3456    0    0]\n",
      " [   0 2721  735]\n",
      " [   0  799 2657]]\n",
      "[1.0, 0.7873263888888888, 0.7688078703703703]\n",
      "[[3456    0    0]\n",
      " [   3 2350 1103]\n",
      " [   0  342 3114]]\n",
      "[1.0, 0.6799768518518519, 0.9010416666666666]\n"
     ]
    }
   ],
   "source": [
    "# Load in the already split Training and Test Set2\n",
    "for i in ['2', '3', '14']:\n",
    "    \n",
    "    xTest_testing = np.load(f'../../testing_data/new_test_data/test_data_64/noise_test_c{i}_64x64_dataset_01.npy', allow_pickle=True)\n",
    "    yTest_testing = np.load(f'../../testing_data/new_test_data/test_data_64/noise_test_c{i}_64x64_labels_01.npy', allow_pickle=True)\n",
    "\n",
    "    # Used for padding\n",
    "    value = 0 \n",
    "\n",
    "    # Section out Perfect - Edge - Screw - Testing Testing - C2 Data\n",
    "    perf_dat = []\n",
    "    edge_dat = []\n",
    "    screw_dat = []\n",
    "\n",
    "    perf_lab = []\n",
    "    edge_lab = []\n",
    "    screw_lab = []\n",
    "\n",
    "\n",
    "    #for idx, labels in tqdm(enumerate(yTest_testing), total=len(yTest_testing)):\n",
    "    for idx, labels in enumerate(yTest_testing):\n",
    "        if labels[0] == 1:\n",
    "            perf_lab.append(labels)\n",
    "            perf_dat.append(xTest_testing[idx])\n",
    "\n",
    "        elif labels[1] == 1:\n",
    "            edge_lab.append(labels)\n",
    "            edge_dat.append(xTest_testing[idx])\n",
    "\n",
    "        elif labels[2] == 1:\n",
    "            screw_lab.append(labels)\n",
    "            screw_dat.append(xTest_testing[idx])\n",
    "\n",
    "    perf_dat = np.asarray(perf_dat)\n",
    "    edge_dat = np.asarray(edge_dat)\n",
    "    screw_dat = np.asarray(screw_dat)\n",
    "\n",
    "    perf_lab = np.asarray(perf_lab)\n",
    "    edge_lab = np.asarray(edge_lab)\n",
    "    screw_lab = np.asarray(screw_lab)\n",
    "\n",
    "\n",
    "    X_test_testing = np.vstack((perf_dat, edge_dat,screw_dat))\n",
    "    y_test_testing = np.vstack((perf_lab, edge_lab, screw_lab))\n",
    "\n",
    "\n",
    "    y_test = np.asarray(y_test_testing)\n",
    "\n",
    "    # Normalize\n",
    "    X_test_testing = norma2(X_test_testing)\n",
    "\n",
    "\n",
    "    X_test_testing = X_test_testing.reshape((X_test_testing.shape[0], 64, 64, 1))\n",
    "    X_test_testing = np.asarray(np.repeat(X_test_testing, 3, 3))\n",
    "\n",
    "\n",
    "    actual_vals = []\n",
    "\n",
    "    for v in y_test:\n",
    "        if all(v == [1,0,0]):\n",
    "            actual_vals.append(0)\n",
    "\n",
    "        elif all(v == [0,1,0]):\n",
    "            actual_vals.append(1)\n",
    "\n",
    "        elif all(v == [0,0,1]):\n",
    "            actual_vals.append(2)\n",
    "\n",
    "\n",
    "    preds = model.predict(X_test_testing)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    pred_vals = []\n",
    "    for v2 in preds:\n",
    "        pred_vals.append(np.argmax(v2))\n",
    "\n",
    "    def percents(conf):\n",
    "        ars = []\n",
    "        for idx, ar in enumerate(conf):\n",
    "            total = np.sum(ar)\n",
    "\n",
    "            output = ar[idx]/total\n",
    "            ars.append(output)\n",
    "        return ars\n",
    "    \n",
    "    conf = confusion_matrix(actual_vals, pred_vals, labels= (0, 1, 2))\n",
    "    print(conf)\n",
    "    coos = percents(conf)\n",
    "    print(coos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autok2",
   "language": "python",
   "name": "autok2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
