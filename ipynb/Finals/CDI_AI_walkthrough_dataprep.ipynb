{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tifffile as tif\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tif(file):\n",
    "    \"\"\"Function to import numpy file and take the np.abs of the data\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    file - (str)\n",
    "        the directory path on where the .tif file image is\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    the data held inside the tif file designated by the User\n",
    "    \n",
    "    \"\"\"\n",
    "    diff3D = tif.imread(file).astype(np.float32)\n",
    "    return diff3D\n",
    "\n",
    "\n",
    "def rot90(m, k=1, axis=2):\n",
    "    \"\"\"Rotate an array k*90 degrees in the counter-clockwise direction around the given axis\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    m = np.swapaxes(m, 2, axis)\n",
    "    m = np.rot90(m, k)\n",
    "    m = np.swapaxes(m, 2, axis)\n",
    "    return m\n",
    "\n",
    "def rotations24(polycube):\n",
    "    \"\"\"Obtain all the 24 different projections of a cube\n",
    "    \n",
    "    \"\"\"\n",
    "    # imagine shape is pointing in axis 0 (up)\n",
    "\n",
    "    # 4 rotations about axis 0\n",
    "    first = rotations4(polycube, 0)\n",
    "\n",
    "    # rotate 180 about axis 1, now shape is pointing down in axis 0\n",
    "    # 4 rotations about axis 0\n",
    "    second = rotations4(rot90(polycube, 2, axis=1), 0)\n",
    "\n",
    "    # rotate 90 or 270 about axis 1, now shape is pointing in axis 2\n",
    "    # 8 rotations about axis 2\n",
    "    third = rotations4(rot90(polycube, axis=1), 2)\n",
    "    fourth = rotations4(rot90(polycube, -1, axis=1), 2)\n",
    "\n",
    "    # rotate about axis 2, now shape is pointing in axis 1\n",
    "    # 8 rotations about axis 1\n",
    "    fifth =  rotations4(rot90(polycube, axis=2), 1)\n",
    "    sixth =  rotations4(rot90(polycube, -1, axis=2), 1)\n",
    "    \n",
    "    return np.concatenate((first, second, third, fourth, fifth, sixth))\n",
    "\n",
    "def rotations4(polycube, axis):\n",
    "    \"\"\"List the four rotations of the given cube about the given axis.\"\"\"\n",
    "    master = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        master.append(rot90(polycube, i, axis))\n",
    "        \n",
    "    return master\n",
    "\n",
    "\n",
    "def slice3D_easy(dataset, labels, diff3D, n_projections, label, Nc=64):\n",
    "    \"\"\"Cut slices out of the center of the 3D array\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    dataset - (np.array)\n",
    "        the dataset array you would like to append the data to\n",
    "    \n",
    "    labels - (np.array)\n",
    "        the labels array you would like to append the label to \n",
    "    \n",
    "    diff3D - (np.array)\n",
    "        the current 3D diffraction image to take slices from\n",
    "    \n",
    "    label - (int)\n",
    "        the label of the dataset you are inputing   \n",
    "    \n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    #Slice 3D array into specified 2D slices - lower theta rotation range from higher theta rotation range\n",
    "    thetas = np.linspace(-45, 45, n_projections, endpoint=False)\n",
    "\n",
    "    for theta in thetas:\n",
    "        slice2D = rotate(diff3D, theta, axes=(0%3, (0+1)%3),\n",
    "                         reshape=False, order=1, mode='constant')[:, int(Nc/2)]\n",
    "\n",
    "        dataset.append(slice2D)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtainin Raw Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the raw pynx_data lives\n",
    "main_dir = '../raw_data/'\n",
    "\n",
    "# Obtainin the list of all the files\n",
    "reflection_list = os.listdir(main_dir)\n",
    "\n",
    "all_files = []\n",
    "\n",
    "# For each reflection in the list - obtain all the sampling rates - obtain all the files\n",
    "for reflection in reflection_list:\n",
    "\n",
    "    sampling_rate_list = sorted(os.listdir(f'{main_dir}{reflection}'))\n",
    "    \n",
    "    for sampling_rate in sampling_rate_list:\n",
    "\n",
    "        files = os.listdir(f'{main_dir}{reflection}/{sampling_rate}/tif')\n",
    "        \n",
    "        adjusted_files = [f'{main_dir}{reflection}/{sampling_rate}/tif/{f}' for f in files]\n",
    "\n",
    "        all_files.append(adjusted_files)\n",
    "        \n",
    "        \n",
    "all_files = np.asarray(all_files)\n",
    "all_files = all_files.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking The Data And Saving It To Individual .Tif Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../intermediate_dir/128x128_2dslices/c1_none_[-110][111][-1-12]_0_to_[100][010][001]__reflection_[1-1-1]_sprate_225_2dslices_dataset.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/480 [00:53<7:08:16, 53.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 128, 128)\n",
      "../intermediate_dir/128x128_2dslices/c3_screw_[111][11-2][1-10]_0_to_[100][010][001]__reflection_[1-1-1]_sprate_225_2dslices_dataset.tif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-475ef528d368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mcrystal_rotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotations24\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcrystal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcrystal_rotations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mslice3D_easy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrystal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_slice_per_90_degree\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-310e271a4a0b>\u001b[0m in \u001b[0;36mslice3D_easy\u001b[0;34m(dataset, labels, diff3D, n_projections, label, Nc)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         slice2D = rotate(diff3D, theta, axes=(0%3, (0+1)%3),\n\u001b[0;32m---> 95\u001b[0;31m                          reshape=False, order=1, mode='constant')[:, int(Nc/2)]\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/miniconda3/envs/tf/lib/python3.7/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(input, angle, axes, reshape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0moa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             affine_transform(ia, matrix, offset, os, oa, order, mode,\n\u001b[0;32m--> 716\u001b[0;31m                              cval, prefilter)\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mjj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_axes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/miniconda3/envs/tf/lib/python3.7/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0;32m--> 458\u001b[0;31m                                       output, order, mode, cval, None, None)\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "save_dataset = []\n",
    "save_labels = []\n",
    "\n",
    "\n",
    "new_all_files = []\n",
    "\n",
    "# Allow the User to pick which sampling rate they would like to calculate\n",
    "user_search_field = '_sprate_225'\n",
    "\n",
    "# Allow the User to set an identifier for the images they are creating\n",
    "type_of_images = '128x128_2dslices'\n",
    "\n",
    "number_of_slice_per_90_degree = 18\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "user_directory_name = 'intermediate_dir'\n",
    "\n",
    "\n",
    "\n",
    "# Data Creation\n",
    "for search_file in all_files:\n",
    "    if user_search_field in search_file:\n",
    "        new_all_files.append(search_file)\n",
    "\n",
    "for file in tqdm(new_all_files, total=len(new_all_files)):\n",
    "    \n",
    "    save_dataset = []\n",
    "    save_labels = []\n",
    "\n",
    "    # importing the raw data files\n",
    "    data = import_tif(file)\n",
    "\n",
    "    # Obtaining the correct label for the data\n",
    "    if '_none_' in file:\n",
    "        label = 0\n",
    "    elif '_edge_' in file:\n",
    "        label = 1\n",
    "    elif '_screw_' in file:\n",
    "        label = 2\n",
    "\n",
    "    splitting_filename = file.split('/')\n",
    "    first_splitting =  ['..'] + [user_directory_name] + [type_of_images] + [splitting_filename[-1][:-4]+'_2dslices_']\n",
    "    \n",
    "    # Creating savenames for the data\n",
    "    data_savename = '/'.join(first_splitting) + 'dataset.tif'\n",
    "    labels_savename = '/'.join(first_splitting) + 'labels.tif'\n",
    "\n",
    "    print(data_savename)\n",
    "    # Raw data is a NxNxN cube\n",
    "    # Obtain all 24 cube rotations for the data\n",
    "    crystal_rotations = rotations24(data)\n",
    "    for crystal in crystal_rotations:    \n",
    "        slice3D_easy(save_dataset, save_labels, crystal, number_of_slice_per_90_degree , label, Nc=image_size)\n",
    "\n",
    "\n",
    "    save_dataset = np.asarray(save_dataset)\n",
    "    save_labels = np.asarray(save_labels)\n",
    "\n",
    "    print(np.shape(save_dataset))\n",
    "    #tif.imsave(data_savename, save_dataset)\n",
    "    #tif.imsave(labels_savename, save_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatonating Data Into Train and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_data(slice_dir, sprate=('sprate_225', ), crys_seperate=('c2_',)):\n",
    "    \"\"\"Allows the User to obtain the data for a specific sampling rate if needed along with being able to\n",
    "    seperate out the training datasets.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    sprate (tuple) - a tuple of strings defining which sample rate names the user would like to obtain data for\n",
    "    \n",
    "    crys_seperate (tuple) - a tuple of strings defining which samples to seperate for the training datasets\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    files = sorted(os.listdir(slice_dir))\n",
    "    \n",
    "    # Obtain All Locations\n",
    "    og_slice_data_list = sorted([f'{slice_dir}{f}' for f in files if '_dataset.tif' in f])\n",
    "    og_slice_labels_list = sorted([f'{slice_dir}{f}' for f in files if '_labels.tif' in f])\n",
    "    \n",
    "    \n",
    "    og_slice_data_list = [f'{f}' for f in og_slice_data_list if any(prate in f for prate in sprate)]\n",
    "    og_slice_labels_list = [f'{f}' for f in og_slice_labels_list if any(prate in f for prate in sprate)]\n",
    "    \n",
    "    seperating_data_list = [f'{f}' for f in og_slice_data_list if any(crys in f for crys in crys_seperate)]\n",
    "    seperating_labels_list = [f'{f}' for f in og_slice_labels_list if any(crys in f for crys in crys_seperate)]\n",
    "    \n",
    "    og_slice_data_list = [f'{f}' for f in og_slice_data_list if not any(crys in f for crys in crys_seperate)]\n",
    "    og_slice_labels_list = [f'{f}' for f in og_slice_labels_list if not any(crys in f for crys in crys_seperate)]   \n",
    "    \n",
    "    return og_slice_data_list, og_slice_labels_list, seperating_data_list, seperating_labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat Next Sections  4 Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once for the training data creation\n",
    "### Once for the creation of C2 stand alone dataset\n",
    "### Once for the creation of C3 stand alone dataset\n",
    "### Once for the creation of C14 stand alone dataset\n",
    "#### Make these by changing the crys_seperate variable in the get_app_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OG Slices\n",
    "og_slice_dir = '../intermediate_dir/128x128_2dslices/'\n",
    "\n",
    "out1 = get_app_data(og_slice_dir)\n",
    "og_slice_data_list, og_slice_labels_list, sep_og_slice_data_list, sep_og_slice_labels_list = out1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_slice_data = np.asarray([])\n",
    "rot_slice_data = np.asarray([])\n",
    "trans_slice_data = np.asarray([])\n",
    "rot_transslice_data = np.asarray([])\n",
    "\n",
    "\n",
    "og_slice_labels = np.asarray([])\n",
    "rot_slice_labels = np.asarray([])\n",
    "trans_slice_labels = np.asarray([])\n",
    "rot_transslice_labels = np.asarray([])\n",
    "\n",
    "\n",
    "# Used To Get Seperate Data - change crys_sep parameter to obtain different testing data\n",
    "data_data = np.hstack((sep_og_slice_data_list))\n",
    "data_labels = np.hstack((sep_og_slice_labels_list))\n",
    "\n",
    "\n",
    "# Used To Get Main Data - set all testing data names into the crys_sep arugment and uncommen\n",
    "# to get the main training data\n",
    "\n",
    "#data_data = np.hstack((og_slice_data_list))\n",
    "#data_labels = np.hstack((og_slice_labels_list))\n",
    "\n",
    "\n",
    "# Normalize Dataset\n",
    "for j, file in tqdm(enumerate(data_data), total=len(data_data)):\n",
    "    #label check \n",
    "    lab_name = data_labels[j][:-11]\n",
    "    if lab_name != file [:-12]:\n",
    "        print('help')\n",
    "        print(lab_name)\n",
    "        print(file [:-12])\n",
    "        print('')\n",
    "    \n",
    "    \n",
    "    # opening and normalizing data\n",
    "    d = tif.imread(file)\n",
    "    l = tif.imread(data_labels[j])\n",
    "    \n",
    "    # Making sure there are no np.nan in the dataset\n",
    "    if np.min(d) < 0:\n",
    "        print(file, np.max(d), np.min(d))\n",
    "\n",
    "    \n",
    "    try:\n",
    "        og_slice_data = np.vstack((og_slice_data, np.asarray(d)))\n",
    "        \n",
    "        if '128x128_2dslices/' in file:\n",
    "            \n",
    "            og_slice_labels = np.vstack((og_slice_labels, np.asarray(l)))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            og_slice_labels = np.vstack((og_slice_labels,np.asarray(l), np.asarray(l)))\n",
    "        \n",
    "    \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        og_slice_data = np.asarray(d)\n",
    "        if '128x128_2dslices/' in file:\n",
    "            og_slice_labels = np.asarray(l)\n",
    "        else:\n",
    "            og_slice_labels = np.vstack((np.asarray(l), np.asarray(l)))\n",
    "        \n",
    "    \n",
    "shape = og_slice_labels.shape\n",
    "\n",
    "og_slice_labels = og_slice_labels.reshape((shape[0] * shape[1]))\n",
    "\n",
    "print(og_slice_data.shape, og_slice_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/testiing_data/test_c2_128x128_dataset_01.npy', og_slice_data)\n",
    "np.save('/testing_data/test_c2_128x128_labels_01.npy', og_slice_labels)\n",
    "\n",
    "\n",
    "#np.save('/testiing_data/test_c3_128x128_dataset_01.npy', og_slice_data)\n",
    "#np.save('/testing_data/test_c3_128x128_labels_01.npy', og_slice_labels)\n",
    "\n",
    "#np.save('/testiing_data/test_c14_128x128_dataset_01.npy', og_slice_data)\n",
    "#np.save('/testing_data/test_c14_128x128_labels_01.npy', og_slice_labels)\n",
    "\n",
    "#np.save('/training_data/training_128x128_dataset_01.npy', og_slice_data)\n",
    "#np.save('/training_data/training_128x128_labels_01.npy', og_slice_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Poisson Noise To Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_train_noise(img, VARIABILITY):\n",
    "    \"\"\"Add random poisson noise to an image\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    img (np) - 2D numpy image\n",
    "    \n",
    "    VARIABILITY - int - the value to be passed into the np.random.poisson function\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    mins = np.min(img)\n",
    "    maxs = np.max(img)\n",
    "\n",
    "    PEAK = VARIABILITY\n",
    "\n",
    "    img = np.random.poisson(img / maxs * PEAK) / PEAK * maxs\n",
    "\n",
    "    # Clip data so there are no negative numbers\n",
    "    img = np.clip(img, mins, maxs)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.load('/testing_data/test_c2_128x128_dataset_01.npy')\n",
    "y_data = np.load('/testing_data/test_c2_128x128_labels_01.npy')\n",
    "\n",
    "#X_data = np.load('/testing_data/test_c3_128x128_dataset_01.npy')\n",
    "#y_data = np.load('/testing_data/test_c3_128x128_labels_01.npy')\n",
    "\n",
    "#X_data = np.load('/testing_data/test_c14_128x128_dataset_01.npy')\n",
    "#y_data = np.load('/testing_data/test_c14_128x128_labels_01.npy')\n",
    "\n",
    "#X_data = np.load('/testing_data/training_128x128_dataset_01.npy')\n",
    "#y_data = np.load('/testing_data/training_128x128_labels_01.npy')\n",
    "\n",
    "\n",
    "# Add noise to the data\n",
    "new_X_data = []\n",
    "new_y_data = []\n",
    "\n",
    "for ids, slices in tqdm(enumerate(X_data), total=len(X_data)):\n",
    "    for value in [4000]:\n",
    "\n",
    "        append_imgs = add_train_noise(slices.copy(), value)\n",
    "\n",
    "        new_X_data.append(append_imgs)\n",
    "        new_y_data.append(y_data[ids])\n",
    "        \n",
    "        \n",
    "new_X_data = np.asarray(new_X_data)\n",
    "new_y_data = np.asarray(new_y_data)\n",
    "\n",
    "new_y_data = to_categorical(new_y_data, 3)\n",
    "        \n",
    "print(new_X_data.shape, new_y_data.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/testing_data/noise_test_c14_128x128_dataset_01.npy', new_X_data)\n",
    "np.save('/testing_data/noise_test_c14_128x128_labels_01.npy', new_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save A 64x64 Version Of All Slices For AutoKeras and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_64 = new_X_data[:, 32:96, 32:96]\n",
    "\n",
    "\n",
    "np.save('../testing_data/noise_test_c2_dataset_01.npy', dataset_64)\n",
    "np.save('../testing_data/noise_test_c2_labels_01.npy', new_y_data)\n",
    "\n",
    "np.save('../testing_data/noise_test_c3_dataset_01.npy', dataset_64)\n",
    "np.save('../testing_data/noise_test_c3_labels_01.npy', new_y_data)\n",
    "\n",
    "np.save('../testing_data/noise_test_c14_dataset_01.npy', dataset_64)\n",
    "np.save('../testing_data/noise_test_c14_labels_01.npy', new_y_data)\n",
    "\n",
    "np.save('../training_data/noise_train_dataset_01.npy', dataset_64)\n",
    "np.save('/..training_data/noise_train_labels_01.npy', new_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autok2",
   "language": "python",
   "name": "autok2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
