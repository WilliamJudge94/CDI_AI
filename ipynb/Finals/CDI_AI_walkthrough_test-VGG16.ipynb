{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Imports and Set Up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from time import sleep\n",
    "#from skimage.transform import resize\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norma2(input_data):\n",
    "    \"\"\"Normalize all data based on their own max values\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    input_data - (np.array)\n",
    "        the full array of all 2D images to normalize based upon their own np.max value\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    The normalized data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    maxies = np.max(input_data, axis=(1,2))\n",
    "    if np.count_nonzero(maxies) != len(input_data):\n",
    "        print('Error - Divide By Zero Found')\n",
    "    output = np.divide(input_data, maxies[:,None, None])\n",
    "\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic TF Imports\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# MODELS AND OPTIMIZERS\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "Nc = 64\n",
    "n_labels = 3\n",
    "\n",
    "base_model=VGG16(input_shape=(Nc,Nc,3),\n",
    "                 include_top=False, )\n",
    "\n",
    "#base_model.layers.pop() #Pop out the current logistic layer\n",
    "tmp = base_model.output\n",
    "\n",
    "#Add a fully connected layer\n",
    "tmp=Flatten()(tmp)\n",
    "\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(n_labels, activation='softmax')(tmp)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "#Fix the first 17 layers\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False \n",
    "    \n",
    "\n",
    "opto = Adam() \n",
    "    \n",
    "model.compile(optimizer=opto, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../trained_model-VGG16/VGG16_trained.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model On Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3456    0    0]\n",
      " [  12 2734  710]\n",
      " [   0 1731 1725]]\n",
      "[1.0, 0.7910879629629629, 0.4991319444444444]\n",
      "[[3426    0   30]\n",
      " [   0 2903  553]\n",
      " [   0 1267 2189]]\n",
      "[0.9913194444444444, 0.8399884259259259, 0.6333912037037037]\n",
      "[[3454    0    2]\n",
      " [   5 2462  989]\n",
      " [   0 1156 2300]]\n",
      "[0.9994212962962963, 0.7123842592592593, 0.6655092592592593]\n"
     ]
    }
   ],
   "source": [
    "# Load in the already split Training and Test Set2\n",
    "for i in ['2', '3', '14']:\n",
    "\n",
    "\n",
    "    xTest_testing = np.load(f'../testing_data/new_test_data/test_data_64/noise_test_c{i}_64x64_dataset_01.npy', allow_pickle=True)\n",
    "    yTest_testing = np.load(f'../testing_data/new_test_data/test_data_64/noise_test_c{i}_64x64_labels_01.npy', allow_pickle=True)\n",
    "\n",
    "    # used for padding\n",
    "    value = 0\n",
    "\n",
    "\n",
    "    # Section out Perfect - Edge - Screw - Testing Testing - C2 Data\n",
    "    perf_dat = []\n",
    "    edge_dat = []\n",
    "    screw_dat = []\n",
    "\n",
    "    perf_lab = []\n",
    "    edge_lab = []\n",
    "    screw_lab = []\n",
    "\n",
    "\n",
    "    #for idx, labels in tqdm(enumerate(yTest_testing), total=len(yTest_testing)):\n",
    "    for idx, labels in enumerate(yTest_testing):\n",
    "        if labels[0] == 1:\n",
    "            perf_lab.append(labels)\n",
    "            perf_dat.append(xTest_testing[idx])\n",
    "\n",
    "        elif labels[1] == 1:\n",
    "            edge_lab.append(labels)\n",
    "            edge_dat.append(xTest_testing[idx])\n",
    "\n",
    "        elif labels[2] == 1:\n",
    "            screw_lab.append(labels)\n",
    "            screw_dat.append(xTest_testing[idx])\n",
    "\n",
    "    perf_dat = np.asarray(perf_dat)\n",
    "    edge_dat = np.asarray(edge_dat)\n",
    "    screw_dat = np.asarray(screw_dat)\n",
    "\n",
    "    perf_lab = np.asarray(perf_lab)\n",
    "    edge_lab = np.asarray(edge_lab)\n",
    "    screw_lab = np.asarray(screw_lab)\n",
    "\n",
    "\n",
    "    X_test_testing = np.vstack((perf_dat, edge_dat,screw_dat))\n",
    "    y_test_testing = np.vstack((perf_lab, edge_lab, screw_lab))\n",
    "\n",
    "\n",
    "    y_test = np.asarray(y_test_testing)\n",
    "\n",
    "    # Normalize\n",
    "    X_test_testing = norma2(X_test_testing)\n",
    "\n",
    "\n",
    "    X_test_testing = X_test_testing.reshape((X_test_testing.shape[0], 64, 64, 1))\n",
    "\n",
    "    X_test_testing = np.asarray(np.repeat(X_test_testing, 3, 3))\n",
    "\n",
    "\n",
    "    actual_vals = []\n",
    "\n",
    "    for v in y_test:\n",
    "        if all(v == [1,0,0]):\n",
    "            actual_vals.append(0)\n",
    "\n",
    "        elif all(v == [0,1,0]):\n",
    "            actual_vals.append(1)\n",
    "\n",
    "        elif all(v == [0,0,1]):\n",
    "            actual_vals.append(2)\n",
    "\n",
    "\n",
    "    preds = model.predict(X_test_testing)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    pred_vals = []\n",
    "\n",
    "    for v2 in preds:\n",
    "        pred_vals.append(np.argmax(v2))\n",
    "\n",
    "\n",
    "    def percents(conf):\n",
    "        ars = []\n",
    "        for idx, ar in enumerate(conf):\n",
    "            total = np.sum(ar)\n",
    "\n",
    "            output = ar[idx]/total\n",
    "            #print(output)\n",
    "            ars.append(output)\n",
    "\n",
    "        return ars\n",
    "\n",
    "    conf = confusion_matrix(actual_vals, pred_vals, labels= (0, 1, 2))\n",
    "    print(conf)\n",
    "    coos = percents(conf)\n",
    "    print(coos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autok2",
   "language": "python",
   "name": "autok2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
